# -*- coding: utf-8 -*-
"""Hacker News - Deployed Code v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a_VdOtZHpLQMt0DsuWIXCEm2djKK3lfO
"""

# Import all Python libraries needed for the project
import numpy as np

import pickle


import torch
import torch.nn as nn


def encode_and_pool(sentences, word2vec_model):
    # Function to encode sentences into word embeddings and apply average pooling
    embeddings = []
    for sentence in sentences:
        # Encode each word in the sentence using Word2Vec
        word_embeddings = [word2vec_model.wv[word] for word in sentence if word in word2vec_model.wv.key_to_index]
        # Apply average pooling to obtain a fixed-length representation
        if word_embeddings:
            sentence_embedding = np.mean(word_embeddings, axis=0)
            embeddings.append(sentence_embedding)
        else:
            # If no word embeddings found (out-of-vocabulary words), use zero vector
            embeddings.append(np.zeros(word2vec_model.vector_size))
    return torch.tensor(embeddings)


# Load word2vec model from pickle
with open('hn_standard_word2vec_model.pkl', 'rb') as f:
    hn_standard_word2vec_model = pickle.load(f)

# Create the model
class MyModel(nn.Module):
    def __init__(self, input_size, hidden_size1, hidden_size2):
        super(MyModel, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size1)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size1, hidden_size2)
        self.relu = nn.ReLU()
        self.fc3 = nn.Linear(hidden_size2, 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x

# Create the model instance
input_size = word2vec_model.vector_size
hidden_size1 = 64
hidden_size2 = 32
model = MyModel(input_size, hidden_size1, hidden_size2)

# Load the saved model state dictionary
model.load_state_dict(torch.load('reg_model.pth'))

# Set the model to evaluation mode
model.eval()

input_sentences = [sentence.split() for sentence in input]
input_embeddings = encode_and_pool(input_sentences, word2vec_model)
input_features = input_embeddings.clone().detach()
output = model(input_features)